{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\czho9\\anaconda3\\envs\\tsf\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.models import load_model\n",
    "import csv\n",
    "from keras.layers import Dense, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changeable parameter\n",
    "train_dir = 'D:\\capstone\\dataset\\similar_10calss\\FGVC_similar_10class_200_train\\CV_0'\n",
    "val_dir = 'D:\\capstone\\dataset\\similar_10calss\\FGVC_similar_10class_200_validation\\CV_0'\n",
    "batch_size = 32\n",
    "epoch_num = 12\n",
    "load_prev_model = False\n",
    "# Make sure to change this to the designated model\n",
    "# prev_model_path = r'test_mini_4_epoch.h5'\n",
    "model_metrics_path = r'InceptionV3_similar_10class_200_bottleneck-history.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-changeable parameter\n",
    "cur_model_path = r'D:\\capstone\\model_save\\InceptionV3_similar_10class_200_bottleneck.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limiting the number of resources used, hopefully this works\n",
    "#It kinda does, CPU usage is only around 40-50% ish\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1600 images belonging to 10 classes.\n",
      "Found 400 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Default configuration from\n",
    "# https://keras.io/preprocessing/image/\n",
    "# With a little bit of change in parameter\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(299, 299),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=(299, 299),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_prev_model == False:\n",
    "    # Just to make sure that this is only being loaded once\n",
    "    base_model = InceptionV3(include_top=False,weights='imagenet',input_shape=(299,299,3))\n",
    "\n",
    "    x = base_model.output\n",
    "    # Output shape is (1,1,2048) no need for GlobalAveragePooling\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Freezing all the base model layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # and then compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "else:\n",
    "    model = load_model(prev_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "50/50 [==============================] - 65s 1s/step - loss: 2.3302 - acc: 0.2056 - val_loss: 1.9354 - val_acc: 0.3500\n",
      "Epoch 2/12\n",
      "50/50 [==============================] - 61s 1s/step - loss: 1.8621 - acc: 0.3612 - val_loss: 1.8776 - val_acc: 0.3650\n",
      "Epoch 3/12\n",
      "50/50 [==============================] - 57s 1s/step - loss: 1.6504 - acc: 0.4300 - val_loss: 1.8928 - val_acc: 0.3650\n",
      "Epoch 4/12\n",
      "50/50 [==============================] - 58s 1s/step - loss: 1.5509 - acc: 0.4569 - val_loss: 1.9747 - val_acc: 0.3800\n",
      "Epoch 5/12\n",
      "50/50 [==============================] - 57s 1s/step - loss: 1.4864 - acc: 0.4800 - val_loss: 1.8254 - val_acc: 0.4225\n",
      "Epoch 6/12\n",
      "50/50 [==============================] - 58s 1s/step - loss: 1.4141 - acc: 0.5194 - val_loss: 1.7636 - val_acc: 0.4425\n",
      "Epoch 7/12\n",
      "50/50 [==============================] - 64s 1s/step - loss: 1.2938 - acc: 0.5550 - val_loss: 1.9855 - val_acc: 0.3675\n",
      "Epoch 8/12\n",
      "50/50 [==============================] - 63s 1s/step - loss: 1.2418 - acc: 0.5663 - val_loss: 1.9001 - val_acc: 0.4150\n",
      "Epoch 9/12\n",
      "50/50 [==============================] - 63s 1s/step - loss: 1.2305 - acc: 0.5850 - val_loss: 1.8240 - val_acc: 0.4350\n",
      "Epoch 10/12\n",
      "50/50 [==============================] - 57s 1s/step - loss: 1.2285 - acc: 0.5619 - val_loss: 2.1510 - val_acc: 0.3950\n",
      "Epoch 11/12\n",
      "50/50 [==============================] - 64s 1s/step - loss: 1.1598 - acc: 0.5969 - val_loss: 1.9245 - val_acc: 0.4300\n",
      "Epoch 12/12\n",
      "50/50 [==============================] - 57s 1s/step - loss: 1.1978 - acc: 0.6031 - val_loss: 1.8800 - val_acc: 0.4025\n"
     ]
    }
   ],
   "source": [
    "# TRAINING CELL\n",
    "num_train_samples = train_generator.samples\n",
    "train_epoch_steps = math.ceil(num_train_samples / batch_size)\n",
    "num_val_samples = validation_generator.samples\n",
    "val_epoch_steps = math.ceil(num_val_samples / batch_size)\n",
    "train_history = model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=train_epoch_steps,\n",
    "                    epochs=epoch_num,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=val_epoch_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the train history in the designated csv file\n",
    "# Note: newline has to be '' due to the way csv writerow works\n",
    "with open(model_metrics_path, 'a+', newline='') as history_file:\n",
    "    csv_writer = csv.writer(history_file)\n",
    "    for e in train_history.epoch:\n",
    "        epoch_number = e\n",
    "        csv_writer.writerow([epoch_number,\n",
    "                            train_history.history['acc'][e],\n",
    "                            train_history.history['loss'][e],\n",
    "                            train_history.history['val_acc'][e],\n",
    "                            train_history.history['val_loss'][e]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally save the model\n",
    "#model.save(prev_model_path)\n",
    "model.save(cur_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
