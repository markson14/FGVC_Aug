{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roidi\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The ipynb version of the test_yolo script modification.\n",
    "Now it works with for the iNaturalist directory structure (1 primary folder, n subfolders of different classes)\n",
    "The output of this script is now a csv file containing the relative filepath and object bounding box of each image\n",
    "IMPORTANT:\n",
    "This script is meant to be put in the same directory as the YOLO Keras project which can be downloaded from here:\n",
    "https://github.com/allanzelener/YAD2K\n",
    "\"\"\"\n",
    "import argparse\n",
    "import colorsys\n",
    "import imghdr\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "from yad2k.models.keras_yolo import yolo_eval, yolo_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changeable params\n",
    "model_path = r'model_data/yolo.h5'\n",
    "assert model_path.endswith('.h5'), 'Keras model must be a .h5 file.'\n",
    "anchors_path = r'model_data/yolo_anchors.txt'\n",
    "classes_path = r'model_data/coco_classes.txt'\n",
    "\n",
    "test_path = r'D:\\Resources\\Inat_Partial\\Aves_Small_SS2_Train\\CV_0'\n",
    "output_path = r'D:\\Dummy\\temp_out\\ss2_cv0_train_bbox.csv'\n",
    "    \n",
    "score_threshold = 0.3\n",
    "iou_threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big block of constant\n",
    "\"\"\"\n",
    "Custom param, to optimize the object detection functionality of YOLO to detect bird\n",
    "\"\"\"\n",
    "# When an object is detected as class 1, it is extremely likely to be a bird\n",
    "# Always return all object instance of class 1 regardless of the number\n",
    "#['bird', 'aeroplane', 'kite']\n",
    "CLASS_1 = set([14, 4, 33])\n",
    "# When an object is detected as class 2, it is likely to be a bird\n",
    "# In 1 image, when there are more than 1 detections and at least 1 of them belong to class 1, \n",
    "# remove all instance of class 2 detection in that scenario\n",
    "# Otherwise if there are only class 2 detections or worse, the best class 2 instance is returned\n",
    "# CLASS_2 = ['person', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra',\n",
    "#             'giraffe', 'banana', 'apple', 'orange', 'carrot', 'hot dog', 'teddy bear']\n",
    "CLASS_2 = set([0, 15, 16, 17, 18, 19, 20, 21, 22,\n",
    "          23, 46, 47, 49, 51, 52, 77])\n",
    "# If there are only class 3 detections in an image, return the entire image coordinate\n",
    "# CLASS_3 = ['bicycle', 'car', 'motorbike', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "#             'fire hydrant', 'stop sign', 'parking meter', 'bench', 'backpack', 'umbrella',\n",
    "#             'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "#             'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "#             'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'sandwich',\n",
    "#             'broccoli', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed',\n",
    "#             'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard',\n",
    "#             'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book',\n",
    "#             'clock', 'vase', 'scissors', 'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_data/yolo.h5 model, anchors, and classes loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roidi\\Anaconda3\\lib\\site-packages\\keras\\models.py:255: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "# Part of coide that shouldn't be touched unless necessary\n",
    "sess = K.get_session()  # TODO: Remove dependence on Tensorflow session.\n",
    "\n",
    "with open(classes_path) as f:\n",
    "    class_names = f.readlines()\n",
    "class_names = [c.strip() for c in class_names]\n",
    "\n",
    "with open(anchors_path) as f:\n",
    "    anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    anchors = np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "yolo_model = load_model(model_path)\n",
    "\n",
    "# Verify model, anchors, and classes are compatible\n",
    "num_classes = len(class_names)\n",
    "num_anchors = len(anchors)\n",
    "# TODO: Assumes dim ordering is channel last\n",
    "model_output_channels = yolo_model.layers[-1].output_shape[-1]\n",
    "assert model_output_channels == num_anchors * (num_classes + 5), \\\n",
    "    'Mismatch between model and given anchor and class sizes. ' \\\n",
    "    'Specify matching anchors and classes with --anchors_path and ' \\\n",
    "    '--classes_path flags.'\n",
    "print('{} model, anchors, and classes loaded.'.format(model_path))\n",
    "\n",
    "# Check if model is fully convolutional, assuming channel last order.\n",
    "model_image_size = yolo_model.layers[0].input_shape[1:3]\n",
    "is_fixed_size = model_image_size != (None, None)\n",
    "\n",
    "# Generate colors for drawing bounding boxes.\n",
    "hsv_tuples = [(x / len(class_names), 1., 1.)\n",
    "              for x in range(len(class_names))]\n",
    "colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "colors = list(\n",
    "    map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n",
    "        colors))\n",
    "random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "random.shuffle(colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "random.seed(None)  # Reset seed to default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate output tensor targets for filtered bounding boxes.\n",
    "# TODO: Wrap these backend operations with Keras layers.\n",
    "yolo_outputs = yolo_head(yolo_model.output, anchors, len(class_names))\n",
    "input_image_shape = K.placeholder(shape=(2, ))\n",
    "boxes, scores, classes = yolo_eval(\n",
    "    yolo_outputs,\n",
    "    input_image_shape,\n",
    "    score_threshold=score_threshold,\n",
    "    iou_threshold=iou_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing subdir Calidris alba\n",
      "Parsing subdir Gallus gallus domesticus\n",
      "Parsing subdir Geococcyx californianus\n",
      "Parsing subdir Phoenicopterus roseus\n",
      "Parsing subdir Picoides villosus\n",
      "Parsing subdir Spheniscus demersus\n",
      "Parsing subdir Sterna striata\n",
      "Parsing subdir Struthio camelus\n",
      "Parsing subdir Thryothorus ludovicianus\n",
      "Parsing subdir Tyrannus verticalis\n"
     ]
    }
   ],
   "source": [
    "# Part that should be changed\n",
    "for subdir_path in os.listdir(test_path):\n",
    "    print('Parsing subdir',subdir_path)\n",
    "    # list of image bounding box string to be saved\n",
    "    image_bb = []\n",
    "    for image_file in os.listdir(os.path.join(test_path, subdir_path)):\n",
    "        cur_image_bb = []\n",
    "        try:\n",
    "            image_type = imghdr.what(os.path.join(test_path, subdir_path, image_file))\n",
    "            if not image_type:\n",
    "                continue\n",
    "        except IsADirectoryError:\n",
    "            continue\n",
    "\n",
    "        image = Image.open(os.path.join(test_path, subdir_path, image_file))\n",
    "        if is_fixed_size:  # TODO: When resizing we can use minibatch input.\n",
    "            resized_image = image.resize(\n",
    "                tuple(reversed(model_image_size)), Image.BICUBIC)\n",
    "            image_data = np.array(resized_image, dtype='float32')\n",
    "        else:\n",
    "            # Due to skip connection + max pooling in YOLO_v2, inputs must have\n",
    "            # width and height as multiples of 32.\n",
    "            new_image_size = (image.width - (image.width % 32),\n",
    "                              image.height - (image.height % 32))\n",
    "            resized_image = image.resize(new_image_size, Image.BICUBIC)\n",
    "            image_data = np.array(resized_image, dtype='float32')\n",
    "            print(image_data.shape)\n",
    "\n",
    "        image_data /= 255.\n",
    "        image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "\n",
    "        out_boxes, out_scores, out_classes = sess.run(\n",
    "            [boxes, scores, classes],\n",
    "            feed_dict={\n",
    "                yolo_model.input: image_data,\n",
    "                input_image_shape: [image.size[1], image.size[0]],\n",
    "                K.learning_phase(): 0\n",
    "            })\n",
    "        # 3 states of bird existence yes (1), maybe (0), no (-1)\n",
    "        bird_exist = -1\n",
    "        if len(set(out_classes) & CLASS_1) > 0:\n",
    "            bird_exist = 1\n",
    "        elif len(set(out_classes) & CLASS_2) > 0:\n",
    "            bird_exist = 0\n",
    "\n",
    "        for i, c in reversed(list(enumerate(out_classes))):\n",
    "            # Depending on the state, skip some prediction\n",
    "            if ((bird_exist == 1 and c not in CLASS_1) or \n",
    "                (bird_exist == 0 and c not in CLASS_2) or \n",
    "                (bird_exist == -1)):\n",
    "                continue\n",
    "            predicted_class = class_names[c]\n",
    "            box = out_boxes[i]\n",
    "            score = out_scores[i]\n",
    "\n",
    "            top, left, bottom, right = box\n",
    "            top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "            left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "            bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "            right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "            # Add a string containing the subdirectory, image name, 4 bounding box coordinates, and confidence\n",
    "            cur_image_bb.append(','.join([subdir_path, image_file, \n",
    "                                       str(top), str(left), str(bottom), str(right),\n",
    "                                       str(score)]))\n",
    "        # If this image has no detected bird, return the bounding box of the whole image\n",
    "        if len(cur_image_bb) == 0:\n",
    "            cur_image_bb.append(','.join([subdir_path, image_file, \n",
    "                                          '0', '0', \n",
    "                                          str(image.size[1]), str(image.size[0]), \n",
    "                                          '-1']))\n",
    "\n",
    "        image_bb += cur_image_bb\n",
    "    # Now write the bounding box data to the output csv file\n",
    "    with open(output_path, 'a+', encoding='utf-8') as op:\n",
    "        for ib in image_bb:\n",
    "            op.write(ib+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
