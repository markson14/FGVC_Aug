{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "This script is used to plot the two dimensional T-SNE representation of a pre-trained model.\n",
    "\n",
    "It utilizes the output of last convolutional layer, creating bottleneck with 1024 features using global Average/MAX pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to be changed\n",
    "\n",
    "\"\"\"\n",
    "Model Parameter\n",
    "Since this script does not require anything beyond convolutional layer, we can just use the pre-trained one\n",
    "In the future if we are going to test fine-tuned model, I will modify this script\n",
    "\"\"\"\n",
    "ModelInit = keras.applications.inception_resnet_v2.InceptionResNetV2\n",
    "# No need for any custom preprocessing, use the one that comes out with the model itself\n",
    "# Make sure this matches the one in ModelInit\n",
    "# TODO: Does not work well with jpeg? Resulted in error when used with generator\n",
    "# For now just use pre-determined rescale value instead\n",
    "model_preprocess_func = keras.applications.inception_resnet_v2.preprocess_input\n",
    "INPUT_SHAPE = (480,480,3)\n",
    "# VGG16 probably wants this to be 1\n",
    "RESCALE_VALUE = 1./255\n",
    "# Might have to keep this slow if the INPUT_SHAPE is large\n",
    "BATCH_SIZE = 16\n",
    "# Either 'avg' or 'max'\n",
    "POOLING = 'avg'\n",
    "SEED = 5703\n",
    "\n",
    "\"\"\"\n",
    "Images Parameter\n",
    "The one that is used to generate conv output array\n",
    "No need to split into train/val, as we are not doing any training with it\n",
    "\"\"\"\n",
    "IMAGE_DIR = r'D:\\Resources\\Inat_Partial\\Aves_Small_SS1_Train_YOLO\\CV_0'\n",
    "\n",
    "\"\"\"\n",
    "Directory of the Convolutional output file, \n",
    "better to have so the pre-computed numpy array we don't have to rerun the predicition every single time\n",
    "if the file not exist in the directory, this script will simply save the conv output in the pre-determined path\n",
    "Name of the file will be generated based on the model name, subset name, and input shape\n",
    "\"\"\"\n",
    "# If YOLO is used, just call it something like SS2-YOLO (anything without space or underscore)\n",
    "SS_NAME = r'SS1-YOLO-CV0'\n",
    "CONV_OUTPUT_DIR = r'D:\\Workspace\\Jupyter\\COMP5703\\rpur7902_local\\Resources'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepath generator\n",
    "CONV_OUTPUT_FILENAME = '_'.join([ModelInit.__name__, SS_NAME, str(INPUT_SHAPE[0]), str(INPUT_SHAPE[1])]) + '.npy'\n",
    "CONV_LABEL_FILENAME = '_'.join([ModelInit.__name__, SS_NAME, str(INPUT_SHAPE[0]), str(INPUT_SHAPE[1])]) + '_label.npy'\n",
    "CONV_TSNE_FILENAME = '_'.join([ModelInit.__name__, SS_NAME, str(INPUT_SHAPE[0]), str(INPUT_SHAPE[1])]) + '_tsne.npy'\n",
    "CONV_OUTPUT_PATH = os.path.join(CONV_OUTPUT_DIR, CONV_OUTPUT_FILENAME)\n",
    "CONV_LABEL_PATH = os.path.join(CONV_OUTPUT_DIR, CONV_LABEL_FILENAME)\n",
    "CONV_TSNE_PATH = os.path.join(CONV_OUTPUT_DIR, CONV_TSNE_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to do any prediction if the output is already saved\n",
    "# Generating a prediction result array, with the size of (num_images, last_convolutional_layer_depth)\n",
    "if os.path.isfile(CONV_OUTPUT_PATH):\n",
    "    X = np.load(CONV_OUTPUT_PATH)\n",
    "    y = np.load(CONV_LABEL_PATH)\n",
    "else:\n",
    "    # Loading model, the slow process\n",
    "    model_notop = ModelInit(include_top=False, weights='imagenet', input_shape=INPUT_SHAPE, pooling=POOLING)\n",
    "    \n",
    "    # Generator preparation\n",
    "    datagen = ImageDataGenerator(rescale=RESCALE_VALUE)\n",
    "    #datagen.preprocessing_function = model_preprocess_func\n",
    "    generator = datagen.flow_from_directory(IMAGE_DIR,\n",
    "                                            target_size=INPUT_SHAPE[:2],\n",
    "                                            class_mode='categorical',\n",
    "                                            batch_size=BATCH_SIZE,\n",
    "                                            shuffle=False,\n",
    "                                            seed=SEED)\n",
    "    # Predicting 3k images is slow, don't run this without GPU\n",
    "    X = model_notop.predict_generator(generator)\n",
    "    # Only works if shuffle is false, cos generator.classes just take the class label in order\n",
    "    y = generator.classes\n",
    "    np.save(CONV_OUTPUT_PATH, X)\n",
    "    np.save(CONV_LABEL_PATH, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Scale and visualize the embedding vectors\n",
    "Based from: \n",
    "http://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html#sphx-glr-auto-examples-manifold-plot-lle-digits-py\n",
    "With a lot of modification\n",
    "\"\"\"\n",
    "def plot_embedding(X, y, title=None):\n",
    "    x_min, x_max = np.min(X, 0), np.max(X, 0)\n",
    "    X = (X - x_min) / (x_max - x_min)\n",
    "    \n",
    "    classes = np.unique(y)\n",
    "    plt.figure(figsize=(20,20))\n",
    "    scatter_paths = [None] * len(classes)\n",
    "    # Plot each classes separately, so we can make the legend properly \n",
    "    for c in classes:\n",
    "        idx = np.where(y==c)\n",
    "        scatter_paths[c] = plt.scatter(X[idx][:,0], X[idx][:,1],s=160)\n",
    "\n",
    "    plt.legend(scatter_paths,\n",
    "           os.listdir(IMAGE_DIR),\n",
    "           scatterpoints=1,\n",
    "           ncol=1,\n",
    "           fontsize=16,\n",
    "           bbox_to_anchor=(1, 1))\n",
    "\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    if title is not None:\n",
    "        plt.title(title, fontsize=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(CONV_TSNE_PATH):\n",
    "    X_tsne = np.load(CONV_TSNE_PATH)\n",
    "else:\n",
    "    # This function is slow if called on large amount of data, make sure to save the image\n",
    "    tsne = TSNE(n_components=2, init='pca', random_state=SEED)\n",
    "    t0 = time()\n",
    "    X_tsne = tsne.fit_transform(X)\n",
    "    print('time taken', (time() - t0))\n",
    "\n",
    "plot_embedding(X_tsne, y, \n",
    "              \"t-SNE embedding of the \" + SS_NAME)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training_time = []\n",
    "model_val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
