{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "This script uses the output of bottleneck (pooled last convolutional) layer of a specific pretrained model as a training input for various machine learning classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "# CROSS VALIDATION\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changeable section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import additional scikit learn model here as necessary\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Extra base model\n",
    "import sys\n",
    "sys.path.append(\"../ResNet152\")\n",
    "from resnet152 import ResNet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to be changed\n",
    "# Mostly similiar with Util/T_SNE_plot, since it uses the same ideas\n",
    "\n",
    "\"\"\"\n",
    "Model Parameter\n",
    "Since this script does not require anything beyond convolutional layer, we can just use the pre-trained one\n",
    "TODO: In the future if we are going to test fine-tuned model, I will modify this script\n",
    "\"\"\"\n",
    "# Add as many base models as necessary\n",
    "BaseModels = []\n",
    "BaseModels.append(keras.applications.inception_resnet_v2.InceptionResNetV2)\n",
    "BaseModels.append(keras.applications.xception.Xception)\n",
    "BaseModels.append(keras.applications.inception_v3.InceptionV3)\n",
    "BaseModels.append(ResNet152)\n",
    "\n",
    "# The preprocessing functions for each base model, make sure that they are in the right order\n",
    "BaseModelPreprocessings = []\n",
    "BaseModelPreprocessings.append(keras.applications.inception_resnet_v2.preprocess_input)\n",
    "BaseModelPreprocessings.append(keras.applications.xception.preprocess_input)\n",
    "BaseModelPreprocessings.append(keras.applications.inception_v3.preprocess_input)\n",
    "BaseModelPreprocessings.append(preprocess_input)\n",
    "\n",
    "# No need for any custom preprocessing, use the one that comes out with the model itself\n",
    "# Make sure this matches the one in BaseModel\n",
    "# TODO: Does not work well with jpeg? Resulted in error when used with generator\n",
    "# For now just use pre-determined rescale value instead\n",
    "# model_preprocess_func = keras.applications.inception_resnet_v2.preprocess_input\n",
    "\n",
    "INPUT_SHAPE = (480,480,3)\n",
    "# Might have to keep this low if the INPUT_SHAPE is large\n",
    "BATCH_SIZE = 32\n",
    "# Either 'avg' or 'max'\n",
    "POOLING = 'avg'\n",
    "SEED = 5703\n",
    "\n",
    "# If YOLO is used, just call it something like SS2-YOLO (anything without space or underscore)\n",
    "# SS_NAME = r'SS1-CV0-Augment10DifferentClass'\n",
    "SS_NAME = r'SS1-CV0'\n",
    "\n",
    "# Whether to use pre-split train-validation or stratified k-fold split\n",
    "IS_PRE_SPLIT = False\n",
    "\n",
    "\"\"\"\n",
    "Images Parameter\n",
    "The one that is used to generate conv output array\n",
    "\"\"\"\n",
    "IMAGE_DIR = r'D:\\Resources\\Inat_Partial\\Aves_Small_SS1'\n",
    "# For averaging the evaluation performance\n",
    "K_FOLD = 5\n",
    "\n",
    "\"\"\"\n",
    "Set this parameter instead in case that pre-split data is preferred over on-the run stratified split\n",
    "For example, If we want to use augmented training data to predict the normal validation\n",
    "\"\"\"\n",
    "TRAIN_DIR = r'D:\\Resources\\Inat_Partial\\Aves_Small_SS1_Augmented10DifferentClass\\CV_0'\n",
    "VAL_DIR = r'D:\\Resources\\Inat_Partial\\Aves_Small_SS1_Validation\\CV_0'\n",
    "\n",
    "\"\"\"\n",
    "Directory of the Convolutional output file, \n",
    "better to have so the pre-computed numpy array we don't have to rerun the predicition every single time\n",
    "if the file not exist in the directory, this script will simply save the conv output in the pre-determined path\n",
    "Name of the file will be generated based on the model name, subset name, and input shape\n",
    "\"\"\"\n",
    "CONV_OUTPUT_DIR = r'D:\\Workspace\\Jupyter\\COMP5703\\rpur7902_local\\Resources'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE this\n",
    "# Append the tested classifier here, make sure to set the random state\n",
    "classifiers = []\n",
    "classifiers.append(LogisticRegression(C=0.1, solver='lbfgs', multi_class='multinomial', random_state=SEED))\n",
    "# classifiers.append(SVC(C=0.1, random_state=SEED))\n",
    "# classifiers.append(RandomForestClassifier(n_estimators=16, max_depth=16, random_state=SEED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unchanged territory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepath and output filename generator\n",
    "conv_output_paths = []\n",
    "conv_label_paths = []\n",
    "# For pre-split data\n",
    "conv_output_training_paths = []\n",
    "conv_output_validation_paths = []\n",
    "conv_label_training_paths = []\n",
    "conv_label_validation_paths = []\n",
    "# To be joined for the output path\n",
    "base_model_names = []\n",
    "for BaseModel in BaseModels:\n",
    "    if IS_PRE_SPLIT:\n",
    "        conv_output_training_filename = ('_'.join([BaseModel.__name__, SS_NAME, 'training',\n",
    "                                                  str(INPUT_SHAPE[0]), str(INPUT_SHAPE[1])]) + \n",
    "                                        '.npy')\n",
    "        conv_output_validation_filename = ('_'.join([BaseModel.__name__, SS_NAME, 'validation',\n",
    "                                                  str(INPUT_SHAPE[0]), str(INPUT_SHAPE[1])]) + \n",
    "                                        '.npy')\n",
    "        conv_label_training_filename = ('_'.join([BaseModel.__name__, SS_NAME, 'training',\n",
    "                                                  str(INPUT_SHAPE[0]), str(INPUT_SHAPE[1])]) + \n",
    "                                        '_label.npy')\n",
    "        conv_label_validation_filename = ('_'.join([BaseModel.__name__, SS_NAME, 'validation',\n",
    "                                                  str(INPUT_SHAPE[0]), str(INPUT_SHAPE[1])]) + \n",
    "                                        '_label.npy')\n",
    "        conv_output_training_path = os.path.join(CONV_OUTPUT_DIR, conv_output_training_filename)\n",
    "        conv_output_validation_path = os.path.join(CONV_OUTPUT_DIR, conv_output_validation_filename)\n",
    "        conv_label_training_path = os.path.join(CONV_OUTPUT_DIR, conv_label_training_filename)\n",
    "        conv_label_validation_path = os.path.join(CONV_OUTPUT_DIR, conv_label_validation_filename)\n",
    "        conv_output_training_paths.append(conv_output_training_path)\n",
    "        conv_output_validation_paths.append(conv_output_validation_path)\n",
    "        conv_label_training_paths.append(conv_label_training_path)\n",
    "        conv_label_validation_paths.append(conv_label_validation_path)\n",
    "    else:\n",
    "        conv_output_filename = '_'.join([BaseModel.__name__, SS_NAME, str(INPUT_SHAPE[0]), str(INPUT_SHAPE[1])]) + '.npy'\n",
    "        conv_label_filename = '_'.join([BaseModel.__name__, SS_NAME, str(INPUT_SHAPE[0]), str(INPUT_SHAPE[1])]) + '_label.npy'\n",
    "        conv_output_path = os.path.join(CONV_OUTPUT_DIR, conv_output_filename)\n",
    "        conv_label_path = os.path.join(CONV_OUTPUT_DIR, conv_label_filename)\n",
    "        conv_output_paths.append(conv_output_path)\n",
    "        conv_label_paths.append(conv_label_path)\n",
    "    base_model_names.append(str(BaseModel.__name__))\n",
    "    \n",
    "output_csv_path = r'./' + SS_NAME + '_' + str(INPUT_SHAPE[0]) + '_' + '_'.join(sorted(base_model_names)) + '_output.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_names = []\n",
    "clf_params = []\n",
    "for clf in classifiers:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    index = 0\n",
    "    while (clf_name + '_' + str(index)) in clf_names:\n",
    "        index += 1\n",
    "    clf_names.append(clf_name + '_' + str(index))\n",
    "    clf_params.append(clf.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode 1, whole image set, cross validated during runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to do any prediction if the output is already saved\n",
    "# Generating a prediction result array, with the size of (num_images, last_convolutional_layer_depth)\n",
    "\n",
    "if IS_PRE_SPLIT == False:\n",
    "    X = None\n",
    "    Y = None\n",
    "    for BaseModel, preprocess_function, conv_output_path, conv_label_path in \\\n",
    "        zip(BaseModels, BaseModelPreprocessings, conv_output_paths, conv_label_paths):\n",
    "            \n",
    "        print('Generating features from model',BaseModel.__name__)\n",
    "        if os.path.isfile(conv_output_path):\n",
    "            X = np.load(conv_output_path) if X is None else np.hstack([X, np.load(conv_output_path)])\n",
    "            # reloading y as is should be fine\n",
    "            y = np.load(conv_label_path)\n",
    "        else:\n",
    "            # Loading model, the slow process\n",
    "            model_notop = BaseModel(include_top=False, weights='imagenet', input_shape=INPUT_SHAPE, pooling=POOLING)\n",
    "\n",
    "            # Generator preparation\n",
    "            datagen = ImageDataGenerator(preprocessing_function=preprocess_function)\n",
    "\n",
    "            generator = datagen.flow_from_directory(IMAGE_DIR,\n",
    "                                                    target_size=INPUT_SHAPE[:2],\n",
    "                                                    class_mode='categorical',\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    shuffle=False,\n",
    "                                                    seed=SEED)\n",
    "            # Predicting 3k images is slow, don't run this without GPU\n",
    "            X_cur_model = model_notop.predict_generator(generator)\n",
    "            # Only works if shuffle is false, cos generator.classes just take the class label in order\n",
    "            y_cur_model = generator.classes\n",
    "            np.save(conv_output_path, X_cur_model)\n",
    "            np.save(conv_label_path, y_cur_model)\n",
    "            X = X_cur_model if X is None else np.hstack([X, X_cur_model])\n",
    "            y = y_cur_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_PRE_SPLIT == False:\n",
    "    clf_trainingtime = []\n",
    "    clf_val_accuracy_mean = []\n",
    "    clf_val_accuracy_std = []\n",
    "    clf_val_recallmacro_mean = []\n",
    "    clf_val_recallmacro_std = []\n",
    "\n",
    "    for index,clf in enumerate(classifiers):\n",
    "        print('Testing', clf_names[index])\n",
    "        cur_clf_trainingtime = 0\n",
    "        cur_clf_accuracy = []\n",
    "        cur_clf_recallmacro = []\n",
    "\n",
    "        # Better not shuffle the data, to match it with the transfer learning\n",
    "        skf = StratifiedKFold(n_splits=K_FOLD,shuffle=False)\n",
    "        for train_index, val_index in skf.split(X, y):\n",
    "            X_train = X[train_index]\n",
    "            y_train = y[train_index]\n",
    "            X_val = X[val_index]\n",
    "            y_val = y[val_index]\n",
    "\n",
    "            time0 = time()\n",
    "            clf.fit(X_train,y_train)\n",
    "            # Only use the first training time\n",
    "            cur_clf_trainingtime = (time() - time0) if cur_clf_trainingtime == 0 else cur_clf_trainingtime\n",
    "\n",
    "            y_pred = clf.predict(X_val)\n",
    "\n",
    "            cur_clf_accuracy.append(accuracy_score(y_val, y_pred))\n",
    "            cur_clf_recallmacro.append(recall_score(y_val, y_pred, average='macro'))\n",
    "\n",
    "        clf_trainingtime.append(cur_clf_trainingtime)\n",
    "        clf_val_accuracy_mean.append(np.mean(cur_clf_accuracy))\n",
    "        clf_val_accuracy_std.append(np.std(cur_clf_accuracy))\n",
    "        clf_val_recallmacro_mean.append(np.mean(cur_clf_recallmacro))\n",
    "        clf_val_recallmacro_std.append(np.std(cur_clf_recallmacro))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode 2, set manually split into train and validation\n",
    "Required when the training and validation data are unequal (e.g. training with augmentation but not validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_PRE_SPLIT == True:\n",
    "    X_train = None\n",
    "    X_val = None\n",
    "    Y_train = None\n",
    "    Y_val = None\n",
    "    for (BaseModel, preprocess_function, \n",
    "         conv_output_training_path, conv_output_validation_path,\n",
    "         conv_label_training_path, conv_label_validation_path) in \\\n",
    "        zip(BaseModels, BaseModelPreprocessings, \n",
    "            conv_output_training_paths, conv_output_validation_paths, \n",
    "            conv_label_training_paths, conv_label_validation_paths):\n",
    "            \n",
    "        print('Generating features from model',BaseModel.__name__)\n",
    "        if os.path.isfile(conv_output_training_path) and os.path.isfile(conv_output_validation_path):\n",
    "            X_train = (np.load(conv_output_training_path) if X_train is None else \n",
    "                       np.hstack([X_train, np.load(conv_output_training_path)]))\n",
    "            X_val = (np.load(conv_output_validation_path) if X_val is None else \n",
    "                       np.hstack([X_val, np.load(conv_output_validation_path)]))\n",
    "            # reloading y as is should be fine\n",
    "            y_train = np.load(conv_label_training_path)\n",
    "            y_val = np.load(conv_label_validation_path)\n",
    "        else:\n",
    "            # Loading model, the slow process\n",
    "            model_notop = BaseModel(include_top=False, weights='imagenet', input_shape=INPUT_SHAPE, pooling=POOLING)\n",
    "\n",
    "            # Generator preparation\n",
    "            datagen = ImageDataGenerator(preprocessing_function=preprocess_function)\n",
    "\n",
    "            train_generator = datagen.flow_from_directory(TRAIN_DIR,\n",
    "                                                    target_size=INPUT_SHAPE[:2],\n",
    "                                                    class_mode='categorical',\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    shuffle=False,\n",
    "                                                    seed=SEED)\n",
    "            val_generator = datagen.flow_from_directory(VAL_DIR,\n",
    "                                                    target_size=INPUT_SHAPE[:2],\n",
    "                                                    class_mode='categorical',\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    shuffle=False,\n",
    "                                                    seed=SEED)\n",
    "            X_train_cur_model = model_notop.predict_generator(train_generator)\n",
    "            X_val_cur_model = model_notop.predict_generator(val_generator)\n",
    "            # Only works if shuffle is false, cos generator.classes just take the class label in order\n",
    "            y_train_cur_model = train_generator.classes\n",
    "            y_val_cur_model = val_generator.classes\n",
    "            np.save(conv_output_training_path, X_train_cur_model)\n",
    "            np.save(conv_output_validation_path, X_val_cur_model)\n",
    "            np.save(conv_label_training_path, y_train_cur_model)\n",
    "            np.save(conv_label_validation_path, y_val_cur_model)\n",
    "            X_train = X_train_cur_model if X_train is None else np.hstack([X_train, X_train_cur_model])\n",
    "            X_val = X_val_cur_model if X_val is None else np.hstack([X_val, X_val_cur_model])\n",
    "            y_train = y_train_cur_model\n",
    "            y_val = y_val_cur_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_PRE_SPLIT == True:\n",
    "    clf_trainingtime = []\n",
    "    clf_val_accuracy_mean = []\n",
    "    clf_val_accuracy_std = []\n",
    "    clf_val_recallmacro_mean = []\n",
    "    clf_val_recallmacro_std = []\n",
    "\n",
    "    for index,clf in enumerate(classifiers):\n",
    "        print('Testing', clf_names[index])\n",
    "        cur_clf_trainingtime = 0\n",
    "        cur_clf_accuracy = []\n",
    "        cur_clf_recallmacro = []\n",
    "\n",
    "        # In mode 2, train and val are already precomputed\n",
    "        time0 = time()\n",
    "        clf.fit(X_train,y_train)\n",
    "        # Only use the first training time\n",
    "        cur_clf_trainingtime = (time() - time0) if cur_clf_trainingtime == 0 else cur_clf_trainingtime\n",
    "\n",
    "        y_pred = clf.predict(X_val)\n",
    "\n",
    "        cur_clf_accuracy.append(accuracy_score(y_val, y_pred))\n",
    "        cur_clf_recallmacro.append(recall_score(y_val, y_pred, average='macro'))\n",
    "\n",
    "        clf_trainingtime.append(cur_clf_trainingtime)\n",
    "        clf_val_accuracy_mean.append(np.mean(cur_clf_accuracy))\n",
    "        clf_val_accuracy_std.append(np.std(cur_clf_accuracy))\n",
    "        clf_val_recallmacro_mean.append(np.mean(cur_clf_recallmacro))\n",
    "        clf_val_recallmacro_std.append(np.std(cur_clf_recallmacro))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe to be saved as csv\n",
    "result_df = pd.DataFrame(columns=['clf_name','clf_params','clf_trainingtime',\n",
    "                                  'clf_val_accuracy_mean','clf_val_accuracy_std',\n",
    "                                  'clf_val_recallmacro_mean','clf_val_recallmacro_std'])\n",
    "result_df.set_index('clf_name', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,clf_name in enumerate(clf_names):\n",
    "    data = [str(clf_params[index]), clf_trainingtime[index], \n",
    "            clf_val_accuracy_mean[index], clf_val_accuracy_std[index], \n",
    "            clf_val_recallmacro_mean[index], clf_val_recallmacro_std[index]]\n",
    "    result_df.loc[clf_name] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(output_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
